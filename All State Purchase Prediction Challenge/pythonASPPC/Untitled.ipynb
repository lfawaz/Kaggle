{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data...\n",
      "removing nulls...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lfawaz/miniconda2/envs/python27/lib/python2.7/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding is_last column ...\n",
      "adding is_final column -predictor-\n",
      "adding viewed total column...\n",
      "converting states to floats...\n",
      "converting car values to floats...\n",
      "merging all datasets...\n",
      "creating final model...\n",
      "Index([u'customer_ID', u'shopping_pt', u'day', u'location', u'group_size',\n",
      "       u'homeowner', u'car_age', u'risk_factor', u'age_oldest',\n",
      "       u'age_youngest', u'married_couple', u'C_previous', u'duration_previous',\n",
      "       u'cost', u'hour', u'minute', u'a', u'b', u'c', u'd', u'e', u'f', u'g',\n",
      "       u'h', u'i', u'AL', u'AR', u'CO', u'CT', u'DC', u'DE', u'FL', u'GA',\n",
      "       u'IA', u'ID', u'IN', u'KS', u'KY', u'MD', u'ME', u'MO', u'MS', u'MT',\n",
      "       u'ND', u'NE', u'NH', u'NM', u'NV', u'NY', u'OH', u'OK', u'OR', u'PA',\n",
      "       u'RI', u'SD', u'TN', u'UT', u'WA', u'WI', u'WV', u'WY', u'total_viewed',\n",
      "       u'is_last', u'is_final'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateparser\n",
    "\n",
    "\n",
    "def load_clean_data():\n",
    "\n",
    "    train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "    print\"load data...\"\n",
    "    model_data = train\n",
    "    ##create hour\n",
    "    model_data['hour'] = model_data['time'].apply(lambda x: x.split(':')[0])\n",
    "    ##create minute\n",
    "    model_data['minute'] = model_data['time'].apply(lambda x: x.split(':')[1])\n",
    "\n",
    "\n",
    "    ##replace car value, risk_fact,C_Previous,duration_previous null with -1\n",
    "    print\"removing nulls...\"\n",
    "    null_columns = ['car_value','risk_factor','C_previous','duration_previous']\n",
    "    for col in null_columns:\n",
    "        model_data[col] = model_data[col].apply(lambda x: -1 if pd.isnull(x) else x)\n",
    "\n",
    "    ############################################################################################   \n",
    "    ##implement is_last column this determines what was the last record the customer looked at##\n",
    "    ############################################################################################\n",
    "    #Select first two columns for faster processing\n",
    "    is_last_data = model_data[['customer_ID','shopping_pt']]\n",
    "    #Set an empty column to is_last\n",
    "    is_last_data['is_last'] = 0\n",
    "\n",
    "    #convert the Pandas frame work to numpy because it is faster to loop through\n",
    "    np_is_last_data = np.asarray(is_last_data)\n",
    "    print \"adding is_last column ...\"\n",
    "    #create a column to indicate if this was the last viewed record\n",
    "    for i in range(len(np_is_last_data)):\n",
    "        if np_is_last_data[i][1] == 1:\n",
    "            np_is_last_data[i - 1][2] = 1\n",
    "\n",
    "    #create the data frame with the is_last column\n",
    "    is_last_data = pd.DataFrame(np_is_last_data, columns=is_last_data.columns.values)\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "    #create a flag to determine if the record was the finally sold record#\n",
    "    ######################################################################\n",
    "\n",
    "    #outer join data with subset of purchases on all the product items\n",
    "    print\"adding is_final column -predictor-\"\n",
    "    #select the purchased record\n",
    "    sold_records_only = model_data[['customer_ID','shopping_pt','A','B','C','D','E','F','G']][(model_data.record_type == 1)]\n",
    "    is_final_merge = pd.merge(model_data[['customer_ID','shopping_pt','A','B','C','D','E','F','G']],sold_records_only,on=['customer_ID','A','B','C','D','E','F','G'], how='outer')\n",
    "\n",
    "    #lamdba function if the value of shopping_pt_y is null since it is outer join then the production was not \n",
    "    #purchased otherwise it was eventually purchase, we will use this column as our predictor\n",
    "    is_final_merge['is_final'] = is_final_merge['shopping_pt_y'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    is_final_merge.rename(columns={'shopping_pt_x':'shopping_pt'}, inplace=True)\n",
    "    is_final_data = is_final_merge[['customer_ID','shopping_pt','is_final']]\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    #create a column to indicate how many times this record was viewed#\n",
    "    ###################################################################\n",
    "    print\"adding viewed total column...\"\n",
    "    #Group by the customer and the product\n",
    "    total_viewed_group_by = model_data.groupby(['customer_ID','A','B','C','D','E','F','G']).size().reset_index()\n",
    "    #relabel the last column as total views\n",
    "    total_viewed_group_by.columns = ['customer_ID', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'total_viewed']\n",
    "\n",
    "    #add total_viewed column to original dataset\n",
    "    total_viewed_data = pd.merge(model_data[['customer_ID','shopping_pt','A','B','C','D','E','F','G']],total_viewed_group_by,on=['customer_ID','A','B','C','D','E','F','G'])[['customer_ID','shopping_pt','total_viewed']]\n",
    "    print\"converting states to floats...\"\n",
    "    ##convert state to floats to allow for categorical data processing\n",
    "    state_dummies = pd.get_dummies(model_data['state'])\n",
    "    state_data = model_data.join(state_dummies)[[u'customer_ID', u'shopping_pt', u'AL', u'AR',           u'CO', u'CT', u'DC', u'DE', u'FL', u'GA', u'IA', u'ID', u'IN', u'KS',           u'KY', u'MD', u'ME', u'MO', u'MS', u'MT', u'ND', u'NE', u'NH', u'NM',           u'NV', u'NY', u'OH', u'OK', u'OR', u'PA', u'RI', u'SD', u'TN', u'UT',           u'WA', u'WI', u'WV', u'WY']]\n",
    "    print\"converting car values to floats...\"\n",
    "    ##convert car values to floats to allow for categorical data processing\n",
    "    car_value_dummies = pd.get_dummies(model_data['car_value'])\n",
    "    car_value_data = model_data.join(car_value_dummies)[['customer_ID','shopping_pt',u'a', u'b',                           u'c',                 u'd',                 u'e',                           u'f',                 u'g',                 u'h',                           u'i']]\n",
    "\n",
    "    ##select all the records that were viewed, remove the record with record_type = 1\n",
    "    original_model_data = model_data[['customer_ID','shopping_pt','day','location','group_size','homeowner','car_age',                                  'risk_factor','age_oldest','age_youngest','married_couple',                                  'C_previous','duration_previous', 'cost','hour','minute']][(model_data.record_type != 1)]\n",
    "    \n",
    "    ##merge all the dataset together to include the columns \n",
    "    print\"merging all datasets...\"\n",
    "    all_new_data = pd.merge(car_value_data,                            pd.merge(state_data,                                     pd.merge(total_viewed_data,                                              pd.merge(is_last_data,is_final_data,                                                        on=['customer_ID','shopping_pt']),                                                           on=['customer_ID','shopping_pt']) ,                                                             on=['customer_ID','shopping_pt']),                                                                on=['customer_ID','shopping_pt'])\n",
    "    #select the final dataset \n",
    "    print\"creating final model...\"\n",
    "    final_model_data = pd.merge(original_model_data,all_new_data,on=['customer_ID','shopping_pt'],how='inner')\n",
    "\n",
    "    return final_model_data\n",
    "\n",
    "def main():\n",
    "    x = load_clean_data()\n",
    "    print x.columns\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
